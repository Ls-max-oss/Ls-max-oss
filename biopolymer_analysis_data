import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from scipy.optimize import minimize
import io # For capturing df.info() output

plt.ioff() # Desativa a exibição interativa de gráficos
sns.set_style("whitegrid")
plt.rcParams["figure.figsize"] = (10, 6)
def capture_df_info(df):
    """Captures df.info() output as a string."""
    buffer = io.StringIO()
    df.info(buf=buffer)
    return buffer.getvalue()

def capture_df_describe(df):
    """Captures df.describe() output as a Markdown table string."""
    return df.describe().to_markdown(index=True, numalign="left", stralign="left")

def load_and_inspect_data(file_path, file_type, encoding="utf-8", delimiter=","):
  print(f"\n--- Carregando e Inspecionando {file_type}: {os.path.basename(file_path)} ---")
  df = pd.read_csv(file_path, delimiter=delimiter, decimal=".", encoding=encoding)
  print("Primeiras 5 linhas:")
  print(df.head())
  print("\nInformações do DataFrame:")
  buffer = io.StringIO()
  df.info(buf=buffer)
  print(buffer.getvalue())
  print("\nEstatísticas Descritivas:")
  print(df.describe())
  print(f"Contagem inicial de linhas: {df.shape[0]}, Colunas: {df.shape[1]}")
  return df, df.head().to_markdown(index=False, numalign="left", stralign="left"), df.describe().to_markdown(index=True, numalign="left", stralign="left"), buffer.getvalue(), df.shape
def clean_and_process_data(df, df_name):
  """Remove colunas 'Unnamed', duplicatas e trata valores ausentes."""
  print(f"\n--- Limpando e Processando {df_name} ---")
  cols_to_drop = [col for col in df.columns if 'Unnamed' in col] # Corrected to only target 'Unnamed'
  if cols_to_drop:
    print(f"Removendo colunas: {cols_to_drop}")
  df = df.drop(columns=cols_to_drop)
  initial_rows = df.shape[0]
  df.drop_duplicates(inplace=True)
  print(f"Duplicatas removidas. Linhas antes: {initial_rows}, Linhas depois: {df.shape[0]}")
  # Ensure 'metodo' and 'ID_Metodo' are treated as strings and not converted to numeric
  cols_to_keep_as_string = ['metodo', 'ID_Metodo']
  # Add other known categorical columns that should not be converted to numeric
  other_categorical_cols = ['Adicao_Metodo', 'Passagem_Agua_Reator']
  cols_to_keep_as_string.extend(other_categorical_cols)


  for col in df.columns:
      if col in cols_to_keep_as_string:
          df[col] = df[col].astype(str).replace('nan', np.nan) # Convert to string, replace 'nan' string with actual NaN
      else:
          if df[col].isnull().any():
              if pd.api.types.is_numeric_dtype(df[col]):
                  df[col].fillna(df[col].mean(), inplace=True)
                  print(f"NaNs na coluna numérica '{col}' preenchidos com a média.")
              else:
                  # For other categorical columns, fill with mode or a placeholder like 'Unknown'
                  mode_val = df[col].mode()[0] if not df[col].mode().empty else 'Unknown'
                  df[col].fillna(mode_val, inplace=True)
                  print(f"NaNs na coluna categórica '{col}' preenchidos com o modo ({mode_val}).")

  # Specific fills for known columns
  if 'Vazao_mL_h' in df.columns and df['Vazao_mL_h'].isnull().any():
    df['Vazao_mL_h'].fillna(0, inplace=True)
    print(f"NaNs na coluna 'Vazao_mL_h' preenchidos com 0 (assumindo 'não aplicável' ou 'zero').")

  if 'Secagem_Temperatura_C' in df.columns and df['Secagem_Temperatura_C'].isnull().any():
    df['Secagem_Temperatura_C'].fillna(25, inplace=True) # Assuming 25°C for ambient temperature
    print(f"NaNs na coluna 'Secagem_Temperatura_C' preenchidos com 25 (assumindo 'temperatura ambiente').")

  # Attempt to convert other object columns to numeric, coercing errors
  for col in df.columns:
    if col not in cols_to_keep_as_string and pd.api.types.is_object_dtype(df[col]):
        try:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        except:
            pass # Do nothing if conversion is not possible

  # Re-fill any NaNs introduced by the above coerce or originally present in numeric columns
  for col in df.columns:
      if df[col].isnull().any():
          if pd.api.types.is_numeric_dtype(df[col]):
              df[col].fillna(df[col].mean(), inplace=True)
          elif col not in cols_to_keep_as_string: # Only fill non-string categorical NaNs with mode or 'Unknown'
              mode_val = df[col].mode()[0] if not df[col].mode().empty else 'Unknown'
              df[col].fillna(mode_val, inplace=True)


  print(f"Shape final de {df_name} após limpeza: {df.shape}")
  print(f"NaNs em {df_name} após limpeza:\n{df.isnull().sum()[df.isnull().sum() > 0]}")
  return df
def consolidate_absorption_data(data_dir):
    """Consolida os arquivos de absorção em um único DataFrame."""
    absorption_files = {
        'FCS': os.path.join(data_dir, 'Absorcao_FCS.csv'),
        'Agua': os.path.join(data_dir, 'Absorcao_Agua.csv'),
        # [cite_start]Changed to comma as delimiter as per prompt [cite: 74]
        'SS_0.9%': os.path.join(data_dir, 'Absorcao_SS _0,9%.csv') # [cite: 8]
    }

    all_absorption_dfs = []
    for liquid_type, file_path in absorption_files.items():
        df, _, _, _, _ = load_and_inspect_data(file_path, f'Absorção ({liquid_type})', delimiter=';') # [cite: 8]
        df = clean_and_process_data(df, f'Absorção ({liquid_type})') # [cite: 9]
        df['Tipo_Liquido'] = liquid_type # [cite: 9]
        all_absorption_dfs.append(df) # [cite: 9]

    df_absorcao_consolidado = pd.concat(all_absorption_dfs, ignore_index=True) # [cite: 9]
    print("\n--- DataFrame de Absorção Consolidado ---")
    print(df_absorcao_consolidado.info())
    print(df_absorcao_consolidado.head())
    print(f"NaNs em DataFrame de Absorção Consolidado:\n{df_absorcao_consolidado.isnull().sum()[df_absorcao_consolidado.isnull().sum() > 0]}")
    return df_absorcao_consolidado
def consolidate_mass_loss_data(data_dir):
    """Consolida os arquivos de perda de massa em um único DataFrame."""
    mass_loss_files = {
        'Agua': os.path.join(data_dir, 'perda_massa_Agua.csv'), # [cite: 10]
        'FCS': os.path.join(data_dir, 'Perda_massa_FCS.csv'), # [cite: 10]
        'SS_0.9%': os.path.join(data_dir, 'perda_massa_SS_0.9%.csv') # [cite: 10]
    }

    all_mass_loss_dfs = []
    for liquid_type, file_path in mass_loss_files.items():
        # [cite_start]Changed to comma as delimiter as per prompt [cite: 74]
        df, _, _, _, _ = load_and_inspect_data(file_path, f'Perda de Massa ({liquid_type})', delimiter=';') # [cite: 10]
        df = clean_and_process_data(df, f'Perda de Massa ({liquid_type})') # [cite: 11]
        df['Tipo_Liquido'] = liquid_type # [cite: 11]
        all_mass_loss_dfs.append(df) # [cite: 11]

    df_perda_consolidado = pd.concat(all_mass_loss_dfs, ignore_index=True) # [cite: 11]
    print("\n--- DataFrame de Perda de Massa Consolidado ---")
    print(df_perda_consolidado.info())
    print(df_perda_consolidado.head())
    print(f"NaNs em DataFrame de Perda de Massa Consolidado:\n{df_perda_consolidado.isnull().sum()[df_perda_consolidado.isnull().sum() > 0]}")
    return df_perda_consolidado
def load_and_process_methods_data(data_dir):
    """Carrega e processa os dados de métodos de obtenção."""
    file_path = os.path.join(data_dir, 'metodos_obtencao_biopolimeros.csv') # [cite: 12]
    # [cite_start]Changed to comma as delimiter as per prompt [cite: 74]
    df_metodos, _, _, _, _ = load_and_inspect_data(file_path, 'Métodos de Obtenção', encoding='latin1', delimiter=';') # [cite: 12]
    df_metodos = clean_and_process_data(df_metodos, 'Métodos de Obtenção') # [cite: 12]
    print(f"NaNs em df_metodos após limpeza:\n{df_metodos.isnull().sum()[df_metodos.isnull().sum() > 0]}")
    return df_metodos
def transform_to_long_format(df, id_vars, value_vars_prefix, new_col_name, time_col_name):
    """Transforma o DataFrame do formato largo para o longo."""
    print(f"\n--- Transformando para formato longo: {new_col_name} ---")
    # Identificar colunas de tempo e valor
    value_vars = [col for col in df.columns if any(col.startswith(prefix) for prefix in value_vars_prefix)] # [cite: 12]

    # [cite_start]Realizar o melt [cite: 13]
    df_long = pd.melt(df, id_vars=id_vars, value_vars=value_vars, var_name='Tempo_Var', value_name=new_col_name) # [cite: 13]

    # Extrair o tempo da coluna Tempo_Var
    df_long[time_col_name] = df_long['Tempo_Var'].str.extract(r'(\d+)h').astype(float) # [cite: 13]

    # Remover a coluna Tempo_Var original
    df_long = df_long.drop(columns=['Tempo_Var']) # [cite: 13]

    print(df_long.info())
    print(df_long.head())
    print(f"NaNs em df_long ({new_col_name}) após transformação para formato longo:\n{df_long.isnull().sum()[df_long.isnull().sum() > 0]}")
    return df_long
def integrate_data(df_main, df_methods):
    """Integra o DataFrame principal com os dados de métodos de obtenção."""
    print("\n--- Integrando dados com métodos de obtenção ---") # [cite: 14]
    # Garantir que as colunas de merge tenham o mesmo tipo e formato
    df_main['metodo'] = df_main['metodo'].astype(str).str.strip() # [cite: 14]
    df_methods['ID_Metodo'] = df_methods['ID_Metodo'].astype(str).str.strip() # [cite: 14]

    print(f"Unique values in df_main['metodo']: {df_main['metodo'].unique()}") # [cite: 14]
    print(f"Unique values in df_methods['ID_Metodo']: {df_methods['ID_Metodo'].unique()}") # [cite: 14]

    # Merge apenas por 'metodo' e 'ID_Metodo'
    df_integrated = pd.merge(df_main, df_methods, left_on='metodo', right_on='ID_Metodo', how='left') # [cite: 14]
    print(df_integrated.info())
    print(df_integrated.head())
    print(f"NaNs em df_integrated após merge:\n{df_integrated.isnull().sum()[df_integrated.isnull().sum() > 0]}")
    return df_integrated
def integrate_data(df_main, df_methods):
    """Integra o DataFrame principal com os dados de métodos de obtenção."""
    print("\n--- Integrando dados com métodos de obtenção ---") # [cite: 14]
    # Garantir que as colunas de merge tenham o mesmo tipo e formato
    df_main['metodo'] = df_main['metodo'].astype(str).str.strip() # [cite: 14]
    df_methods['ID_Metodo'] = df_methods['ID_Metodo'].astype(str).str.strip().str.replace(' ', '') # Remove space from ID_Metodo

    print(f"Unique values in df_main['metodo']: {df_main['metodo'].unique()}") # [cite: 14]
    print(f"Unique values in df_methods['ID_Metodo']: {df_methods['ID_Metodo'].unique()}") # [cite: 14]

    # Merge apenas por 'metodo' e 'ID_Metodo'
    df_integrated = pd.merge(df_main, df_methods, left_on='metodo', right_on='ID_Metodo', how='left') # [cite: 14]
    print(df_integrated.info())
    print(df_integrated.head())
    print(f"NaNs em df_integrated após merge:\n{df_integrated.isnull().sum()[df_integrated.isnull().sum() > 0]}")
    return df_integrated
def perform_eda_and_visualizations(df_absorcao, df_perda, reports_dir):
    """Realiza a Análise Exploratória de Dados (EDA) e gera visualizações."""
    print("\n--- Realizando Análise Exploratória de Dados (EDA) ---") # [cite: 15]

    # 1. Distribuição das variáveis numéricas chave
    print("\n1. Distribuição das variáveis numéricas chave") # [cite: 16]
    plt.figure(figsize=(10, 6))
    sns.histplot(df_absorcao['CW_gg_Unificado'], kde=True)
    plt.title('Distribuição de Cw (Absorção)')
    plt.xlabel('Cw (g/g)')
    plt.ylabel('Frequência')
    plt.tight_layout()
    plt.savefig(os.path.join(reports_dir, 'distribuicao_cw_absorcao.png')) # [cite: 16]
    plt.close()

    plt.figure(figsize=(10, 6))
    sns.histplot(df_perda['Mp_Percentual_Unificado'], kde=True)
    plt.title('Distribuição de Mp (Perda de Massa)')
    plt.xlabel('Mp (%)')
    plt.ylabel('Frequência')
    plt.tight_layout()
    plt.savefig(os.path.join(reports_dir, 'distribuicao_mp_perda_massa.png')) # [cite: 16]
    plt.close()

    # 2. Relação entre Tempo e Absorção/Perda de Massa por Tipo de Líquido
    print("\n2. Relação entre Tempo e Absorção/Perda de Massa por Tipo de Líquido") # [cite: 17]
    plt.figure(figsize=(12, 7))
    sns.lineplot(data=df_absorcao, x='Tempo_h', y='CW_gg_Unificado', hue='Tipo_Liquido', errorbar='sd')
    plt.title('Cw (Absorção) ao longo do Tempo por Tipo de Líquido')
    plt.xlabel('Tempo (h)')
    plt.ylabel('Cw (g/g)')
    plt.savefig(os.path.join(reports_dir, 'cw_tempo_tipo_liquido.png')) # [cite: 17]
    plt.close()

    plt.figure(figsize=(12, 7))
    sns.lineplot(data=df_perda, x='Tempo_h', y='Mp_Percentual_Unificado', hue='Tipo_Liquido', errorbar='sd')
    plt.title('Mp (Perda de Massa) ao longo do Tempo por Tipo de Líquido')
    plt.xlabel('Tempo (h)') # [cite: 18]
    plt.ylabel('Mp (%)') # [cite: 18]
    plt.savefig(os.path.join(reports_dir, 'mp_tempo_tipo_liquido.png')) # [cite: 18]
    plt.close()

    # 3. Comparação de Absorção/Perda de Massa por Método de Obtenção
    print("\n3. Comparação de Absorção/Perda de Massa por Método de Obtenção") # [cite: 19]
    plt.figure(figsize=(12, 7))
    sns.boxplot(data=df_absorcao, x='metodo', y='CW_gg_Unificado')
    plt.title('Cw (Absorção) por Método de Obtenção')
    plt.xlabel('Método de Obtenção')
    plt.ylabel('Cw (g/g)')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.savefig(os.path.join(reports_dir, 'cw_metodo_obtencao.png')) # [cite: 19]
    plt.close()

    plt.figure(figsize=(12, 7))
    sns.boxplot(data=df_perda, x='metodo', y='Mp_Percentual_Unificado')
    plt.title('Mp (Perda de Massa) por Método de Obtenção')
    plt.xlabel('Método de Obtenção')
    plt.ylabel('Mp (%)')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.savefig(os.path.join(reports_dir, 'mp_metodo_obtencao.png')) # [cite: 19]
    plt.close()

    # 4. Correlação entre variáveis numéricas (ex: massa_seca_inicial vs Cw/Mp)
    print("\n4. Correlação entre variáveis numéricas") # [cite: 20]
    plt.figure(figsize=(8, 6))
    sns.scatterplot(data=df_absorcao, x='massa_seca_inicial', y='CW_gg_Unificado', hue='Tipo_Liquido', alpha=0.7)
    plt.title('Massa Seca Inicial vs Cw (Absorção)')
    plt.xlabel('Massa Seca Inicial (g)')
    plt.ylabel('Cw (g/g)')
    plt.savefig(os.path.join(reports_dir, 'massa_seca_inicial_vs_cw.png')) # [cite: 20]
    plt.close()

    plt.figure(figsize=(8, 6))
    sns.scatterplot(data=df_perda, x='peso_seco_inicial', y='Mp_Percentual_Unificado', hue='Tipo_Liquido', alpha=0.7)
    plt.title('Peso Seco Inicial vs Mp (Perda de Massa)')
    plt.xlabel('Peso Seco Inicial (g)')
    plt.ylabel('Mp (%)')
    plt.savefig(os.path.join(reports_dir, 'peso_seco_inicial_vs_mp.png')) # [cite: 20]
    plt.close()

    # --- NEW EDA: Incorporating Obtaining Features ---
    # Define obtaining features for plotting. Adjust names based on actual columns after merge
    obtaining_numeric_features = [
        'Concentracao_Quitosana_pct', 'Vazao_mL_h', 'Secagem_Temperatura_C',
        'pH', 'Tempo_Agitacao_h', 'Velocidade_Agitacao_rpm', 'Pressao_kPa'
    ]
    obtaining_categorical_features = ['Adicao_Metodo', 'Passagem_Agua_Reator']

    obtaining_numeric_features_abs_exist = [f for f in obtaining_numeric_features if f in df_absorcao.columns]
    obtaining_categorical_features_abs_exist = [f for f in obtaining_categorical_features if f in df_absorcao.columns]
    obtaining_numeric_features_perda_exist = [f for f in obtaining_numeric_features if f in df_perda.columns]
    obtaining_categorical_features_perda_exist = [f for f in obtaining_categorical_features if f in df_perda.columns]

    # 5. Relação com Novas Features de Obtenção (Scatter plots for numeric)
    print("\n5. Relação entre Variáveis de Obtenção Numéricas e Targets")
    for feature in obtaining_numeric_features_abs_exist:
        plt.figure(figsize=(10, 6))
        sns.scatterplot(data=df_absorcao, x=feature, y='CW_gg_Unificado', hue='Tipo_Liquido', alpha=0.7)
        plt.title(f'Cw (Absorção) vs. {feature.replace("_", " ")}')
        plt.xlabel(feature.replace('_', ' '))
        plt.ylabel('Cw (g/g)')
        plt.tight_layout()
        plt.savefig(os.path.join(reports_dir, f'cw_vs_{feature.lower()}.png'))
        plt.close()

    for feature in obtaining_numeric_features_perda_exist:
        plt.figure(figsize=(10, 6))
        sns.scatterplot(data=df_perda, x=feature, y='Mp_Percentual_Unificado', hue='Tipo_Liquido', alpha=0.7)
        plt.title(f'Mp (Perda de Massa) vs. {feature.replace("_", " ")}')
        plt.xlabel(feature.replace('_', ' '))
        plt.ylabel('Mp (%)')
        plt.tight_layout()
        plt.savefig(os.path.join(reports_dir, f'mp_vs_{feature.lower()}.png'))
        plt.close()

    # 6. Box/Violin Plots para Features Categóricas de Obtenção
    print("\n6. Comparação de Cw/Mp por Features de Obtenção Categóricas")
    for feature in obtaining_categorical_features_abs_exist:
        plt.figure(figsize=(12, 7))
        sns.boxplot(data=df_absorcao, x=feature, y='CW_gg_Unificado')
        plt.title(f'Cw (Absorção) por {feature.replace("_", " ")}')
        plt.xlabel(feature.replace('_', ' '))
        plt.ylabel('Cw (g/g)')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.savefig(os.path.join(reports_dir, f'cw_boxplot_{feature.lower()}.png'))
        plt.close()

    for feature in obtaining_categorical_features_perda_exist:
        plt.figure(figsize=(12, 7))
        sns.boxplot(data=df_perda, x=feature, y='Mp_Percentual_Unificado')
        plt.title(f'Mp (Perda de Massa) por {feature.replace("_", " ")}')
        plt.xlabel(feature.replace('_', ' '))
        plt.ylabel('Mp (%)')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.savefig(os.path.join(reports_dir, f'mp_boxplot_{feature.lower()}.png'))
        plt.close()

    # 7. Histograms for all numeric features (including obtaining features)
    print("\n7. Distribuições de Features Numéricas")
    all_numeric_cols_abs = df_absorcao.select_dtypes(include=np.number).columns.tolist()
    all_numeric_cols_perda = df_perda.select_dtypes(include=np.number).columns.tolist()

    for col in all_numeric_cols_abs:
        # Avoid replotting already plotted key variables
        if col not in ['Tempo_h', 'CW_gg_Unificado', 'massa_seca_inicial']:
            plt.figure(figsize=(8, 5))
            sns.histplot(df_absorcao[col].dropna(), kde=True)
            plt.title(f'Distribuição de {col.replace("_", " ")}')
            plt.xlabel(col.replace('_', ' '))
            plt.ylabel('Frequência')
            plt.tight_layout()
            plt.savefig(os.path.join(reports_dir, f'hist_{col.lower()}.png'))
            plt.close()

    for col in all_numeric_cols_perda:
        # Avoid replotting already plotted key variables
        if col not in ['Tempo_h', 'Mp_Percentual_Unificado', 'peso_seco_inicial']:
            plt.figure(figsize=(8, 5))
            sns.histplot(df_perda[col].dropna(), kde=True)
            plt.title(f'Distribuição de {col.replace("_", " ")}')
            plt.xlabel(col.replace('_', ' '))
            plt.ylabel('Frequência')
            plt.tight_layout()
            plt.savefig(os.path.join(reports_dir, f'hist_{col.lower()}.png'))
            plt.close()

    # 8. Correlation Heatmaps
    print("\n8. Heatmaps de Correlação entre Variáveis Numéricas")
    plt.figure(figsize=(14, 12))
    sns.heatmap(df_absorcao[all_numeric_cols_abs].corr(), annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
    plt.title('Heatmap de Correlação - Dados de Absorção (com Features de Obtenção)')
    plt.tight_layout()
    plt.savefig(os.path.join(reports_dir, 'heatmap_correlacao_absorcao.png'))
    plt.close()

    plt.figure(figsize=(14, 12))
    sns.heatmap(df_perda[all_numeric_cols_perda].corr(), annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
    plt.title('Heatmap de Correlação - Dados de Perda de Massa (com Features de Obtenção)')
    plt.tight_layout()
    plt.savefig(os.path.join(reports_dir, 'heatmap_correlacao_perda_massa.png'))
    plt.close()

    print("Visualizações geradas e salvas na pasta reports.")
def implement_predictive_models(df_absorcao, df_perda, reports_dir):
    """Implementa modelos preditivos para Cw e Mp."""
    print("\n--- Implementando Modelos Preditivos ---") # [cite: 21]

    model_results = {
        'absorption': {},
        'mass_loss': {}
    }
    best_models = {}

    # Define all potential features, including those from methods of obtaining
    # Ensure these are the actual column names in the integrated dataframes.
    obtaining_numeric_features = [
        'Concentracao_Quitosana_pct', 'Vazao_mL_h', 'Secagem_Temperatura_C',
        'pH', 'Tempo_Agitacao_h', 'Velocidade_Agitacao_rpm', 'Pressao_kPa'
    ]
    obtaining_categorical_features = ['Adicao_Metodo', 'Passagem_Agua_Reator'] # Example categorical, add others if present

    # Target columns
    target_absorcao = 'CW_gg_Unificado' # [cite: 21]
    target_perda = 'Mp_Percentual_Unificado' # [cite: 26]

    # --- Absorption Model (CW) ---
    print("\n--- Modelagem para Absorção (Cw) ---")

    # Select features that exist in the dataframe and are relevant
    numeric_features_abs = ['Tempo_h', 'massa_seca_inicial'] + [col for col in obtaining_numeric_features if col in df_absorcao.columns]
    categorical_features_abs = ['Tipo_Liquido', 'metodo'] + [col for col in obtaining_categorical_features if col in df_absorcao.columns]

    # Drop columns that are definitely not features for prediction
    cols_to_drop_from_features_abs = ['id_amostra', 'Massa_Umida_Final_Unificado', 'ID_Metodo'] # ID_Metodo is redundant after merge
    all_features_to_encode_abs = numeric_features_abs + categorical_features_abs

    # Create a copy to avoid SettingWithCopyWarning
    df_absorcao_processed = df_absorcao[all_features_to_encode_abs + [target_absorcao]].copy()
    
    # Handle NaNs in the final feature set before one-hot encoding, if any remain
    # This might be needed if original data had NaNs in obtaining features that weren't caught by specific fills
    for col in df_absorcao_processed.columns:
        if df_absorcao_processed[col].isnull().any():
            if pd.api.types.is_numeric_dtype(df_absorcao_processed[col]):
                df_absorcao_processed[col].fillna(df_absorcao_processed[col].mean(), inplace=True)
            else:
                mode_val = df_absorcao_processed[col].mode()[0]
                df_absorcao_processed[col].fillna(mode_val, inplace=True)

    # One-hot encode categorical features [cite: 22]
    df_absorcao_encoded = pd.get_dummies(df_absorcao_processed, columns=categorical_features_abs, drop_first=True)

    # Drop target from X for modeling
    X_abs = df_absorcao_encoded.drop(columns=[target_absorcao])
    y_abs = df_absorcao_encoded[target_absorcao]

    # Handle any remaining NaNs after encoding (e.g., if a category became NaN after dropna during encoding)
    # This is critical as models don't handle NaNs well
    X_abs = X_abs.dropna(axis=1, how='all') # Drop columns that are all NaN
    y_abs = y_abs[X_abs.index] # Align y with X

    # Drop rows where target is NaN (if any)
    nan_target_rows = y_abs.isnull()
    if nan_target_rows.any():
        print(f"Removing {nan_target_rows.sum()} rows with NaN targets in absorption data.")
        X_abs = X_abs[~nan_target_rows]
        y_abs = y_abs[~nan_target_rows]


    print(f"Shape de X_abs depois do pré-processamento: {X_abs.shape}") # [cite: 24]
    print(f"Shape de y_abs depois do pré-processamento: {y_abs.shape}") # [cite: 24]

    if X_abs.empty or y_abs.empty:
        print("Dados de absorção insuficientes para modelagem após tratamento de NaNs.")
    else:
        X_train_abs, X_test_abs, y_train_abs, y_test_abs = train_test_split(X_abs, y_abs, test_size=0.2, random_state=42) # [cite: 24]
        print(f"Shape de X_train_abs: {X_train_abs.shape}, y_train_abs: {y_train_abs.shape}") # [cite: 24]
        print("Iniciando treinamento dos modelos de absorção...")

        # Linear Regression
        model_lr_abs = LinearRegression()
        model_lr_abs.fit(X_train_abs, y_train_abs)
        y_pred_lr_abs = model_lr_abs.predict(X_test_abs)
        model_results['absorption']['LinearRegression'] = {
            'R2': r2_score(y_test_abs, y_pred_lr_abs),
            'RMSE': np.sqrt(mean_squared_error(y_test_abs, y_pred_lr_abs)),
            'MAE': mean_absolute_error(y_test_abs, y_pred_lr_abs)
        }
        print(f"\nModelo de Absorção (Cw) - Linear Regression - R²: {model_results['absorption']['LinearRegression']['R2']:.4f}, RMSE: {model_results['absorption']['LinearRegression']['RMSE']:.4f}, MAE: {model_results['absorption']['LinearRegression']['MAE']:.4f}")

        # RandomForestRegressor with GridSearchCV
        param_grid_rf = {'n_estimators': [50, 100], 'max_depth': [5, 10]} # Reduced for quicker execution
        grid_search_rf_abs = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=3, n_jobs=-1, scoring='r2')
        grid_search_rf_abs.fit(X_train_abs, y_train_abs)
        model_rf_abs = grid_search_rf_abs.best_estimator_
        y_pred_rf_abs = model_rf_abs.predict(X_test_abs)
        model_results['absorption']['RandomForest'] = {
            'Best_Params': grid_search_rf_abs.best_params_,
            'R2': r2_score(y_test_abs, y_pred_rf_abs),
            'RMSE': np.sqrt(mean_squared_error(y_test_abs, y_pred_rf_abs)),
            'MAE': mean_absolute_error(y_test_abs, y_pred_rf_abs)
        }
        print(f"\nModelo de Absorção (Cw) - RandomForest (Best Params: {model_results['absorption']['RandomForest']['Best_Params']}) - R²: {model_results['absorption']['RandomForest']['R2']:.4f}, RMSE: {model_results['absorption']['RandomForest']['RMSE']:.4f}, MAE: {model_results['absorption']['RandomForest']['MAE']:.4f}")

        # GradientBoostingRegressor with GridSearchCV
        param_grid_gb = {'n_estimators': [50, 100], 'learning_rate': [0.05, 0.1]} # Reduced for quicker execution
        grid_search_gb_abs = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid_gb, cv=3, n_jobs=-1, scoring='r2')
        grid_search_gb_abs.fit(X_train_abs, y_train_abs)
        model_gb_abs = grid_search_gb_abs.best_estimator_
        y_pred_gb_abs = model_gb_abs.predict(X_test_abs)
        model_results['absorption']['GradientBoosting'] = {
            'Best_Params': grid_search_gb_abs.best_params_,
            'R2': r2_score(y_test_abs, y_pred_gb_abs),
            'RMSE': np.sqrt(mean_squared_error(y_test_abs, y_pred_gb_abs)),
            'MAE': mean_absolute_error(y_test_abs, y_pred_gb_abs)
        }
        print(f"\nModelo de Absorção (Cw) - GradientBoosting (Best Params: {model_results['absorption']['GradientBoosting']['Best_Params']}) - R²: {model_results['absorption']['GradientBoosting']['R2']:.4f}, RMSE: {model_results['absorption']['GradientBoosting']['RMSE']:.4f}, MAE: {model_results['absorption']['GradientBoosting']['MAE']:.4f}")

        # Select best model for absorption based on R2
        best_abs_model_name = max(model_results['absorption'], key=lambda k: model_results['absorption'][k]['R2'] if 'R2' in model_results['absorption'][k] else -np.inf)
        if best_abs_model_name == 'LinearRegression': best_models['absorption'] = model_lr_abs
        elif best_abs_model_name == 'RandomForest': best_models['absorption'] = model_rf_abs
        else: best_models['absorption'] = model_gb_abs

        # Feature Importance for the best ensemble model (if applicable)
        if hasattr(best_models['absorption'], 'feature_importances_'):
            importances_abs = best_models['absorption'].feature_importances_
            feature_names_abs = X_abs.columns
            feature_importance_df_abs = pd.DataFrame({'Feature': feature_names_abs, 'Importance': importances_abs}).sort_values(by='Importance', ascending=False)
            model_results['absorption']['Feature_Importance'] = feature_importance_df_abs.to_dict('records')

            plt.figure(figsize=(10, 6))
            sns.barplot(x='Importance', y='Feature', data=feature_importance_df_abs.head(10))
            plt.title(f'Top 10 Feature Importances - Absorção ({best_abs_model_name})')
            plt.tight_layout()
            plt.savefig(os.path.join(reports_dir, 'feature_importance_absorption.png'))
            plt.close()

        # Real vs Predicted Plot for Absorption
        plt.figure(figsize=(8, 6))
        plt.scatter(y_test_abs, best_models['absorption'].predict(X_test_abs), alpha=0.6)
        plt.plot([y_test_abs.min(), y_test_abs.max()], [y_test_abs.min(), y_test_abs.max()], 'r--')
        plt.title(f'Real vs. Previsto - Absorção ({best_abs_model_name})')
        plt.xlabel('Valor Real de Cw (g/g)')
        plt.ylabel('Valor Previsto de Cw (g/g)')
        plt.savefig(os.path.join(reports_dir, 'real_vs_predicted_absorption.png'))
        plt.close()

    # --- Mass Loss Model (Mp) ---
    print("\n--- Modelagem para Perda de Massa (Mp) ---")

    numeric_features_perda = ['Tempo_h', 'peso_seco_inicial'] + [col for col in obtaining_numeric_features if col in df_perda.columns]
    categorical_features_perda = ['Tipo_Liquido', 'metodo'] + [col for col in obtaining_categorical_features if col in df_perda.columns]

    cols_to_drop_from_features_perda = ['id_amostra', 'Peso_Seco_Final_Unificado', 'ID_Metodo']
    all_features_to_encode_perda = numeric_features_perda + categorical_features_perda

    df_perda_processed = df_perda[all_features_to_encode_perda + [target_perda]].copy()

    for col in df_perda_processed.columns:
        if df_perda_processed[col].isnull().any():
            if pd.api.types.is_numeric_dtype(df_perda_processed[col]):
                df_perda_processed[col].fillna(df_perda_processed[col].mean(), inplace=True)
            else:
                mode_val = df_perda_processed[col].mode()[0]
                df_perda_processed[col].fillna(mode_val, inplace=True)

    df_perda_encoded = pd.get_dummies(df_perda_processed, columns=categorical_features_perda, drop_first=True)

    X_perda = df_perda_encoded.drop(columns=[target_perda])
    y_perda = df_perda_encoded[target_perda]

    X_perda = X_perda.dropna(axis=1, how='all')
    y_perda = y_perda[X_perda.index]

    nan_target_rows_perda = y_perda.isnull()
    if nan_target_rows_perda.any():
        print(f"Removing {nan_target_rows_perda.sum()} rows with NaN targets in mass loss data.")
        X_perda = X_perda[~nan_target_rows_perda]
        y_perda = y_perda[~nan_target_rows_perda]

    print(f"Shape de X_perda depois do pré-processamento: {X_perda.shape}") # [cite: 28]
    print(f"Shape de y_perda depois do pré-processamento: {y_perda.shape}") # [cite: 28]

    if X_perda.empty or y_perda.empty:
        print("Dados de perda de massa insuficientes para modelagem após tratamento de NaNs.")
    else:
        X_train_perda, X_test_perda, y_train_perda, y_test_perda = train_test_split(X_perda, y_perda, test_size=0.2, random_state=42) # [cite: 28]
        print(f"Shape de X_train_perda: {X_train_perda.shape}, y_train_perda: {y_train_perda.shape}") # [cite: 28]
        print("Iniciando treinamento dos modelos de perda de massa...")

        # Linear Regression
        model_lr_perda = LinearRegression()
        model_lr_perda.fit(X_train_perda, y_train_perda)
        y_pred_lr_perda = model_lr_perda.predict(X_test_perda)
        model_results['mass_loss']['LinearRegression'] = {
            'R2': r2_score(y_test_perda, y_pred_lr_perda),
            'RMSE': np.sqrt(mean_squared_error(y_test_perda, y_pred_lr_perda)),
            'MAE': mean_absolute_error(y_test_perda, y_pred_lr_perda)
        }
        print(f"\nModelo de Perda de Massa (Mp) - Linear Regression - R²: {model_results['mass_loss']['LinearRegression']['R2']:.4f}, RMSE: {model_results['mass_loss']['LinearRegression']['RMSE']:.4f}, MAE: {model_results['mass_loss']['LinearRegression']['MAE']:.4f}")

        # RandomForestRegressor with GridSearchCV
        grid_search_rf_perda = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=3, n_jobs=-1, scoring='r2')
        grid_search_rf_perda.fit(X_train_perda, y_train_perda)
        model_rf_perda = grid_search_rf_perda.best_estimator_
        y_pred_rf_perda = model_rf_perda.predict(X_test_perda)
        model_results['mass_loss']['RandomForest'] = {
            'Best_Params': grid_search_rf_perda.best_params_,
            'R2': r2_score(y_test_perda, y_pred_rf_perda),
            'RMSE': np.sqrt(mean_squared_error(y_test_perda, y_pred_rf_perda)),
            'MAE': mean_absolute_error(y_test_perda, y_pred_rf_perda)
        }
        print(f"\nModelo de Perda de Massa (Mp) - RandomForest (Best Params: {model_results['mass_loss']['RandomForest']['Best_Params']}) - R²: {model_results['mass_loss']['RandomForest']['R2']:.4f}, RMSE: {model_results['mass_loss']['RandomForest']['RMSE']:.4f}, MAE: {model_results['mass_loss']['RandomForest']['MAE']:.4f}")

        # GradientBoostingRegressor with GridSearchCV
        grid_search_gb_perda = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid_gb, cv=3, n_jobs=-1, scoring='r2')
        grid_search_gb_perda.fit(X_train_perda, y_train_perda)
        model_gb_perda = grid_search_gb_perda.best_estimator_
        y_pred_gb_perda = model_gb_perda.predict(X_test_perda)
        model_results['mass_loss']['GradientBoosting'] = {
            'Best_Params': grid_search_gb_perda.best_params_,
            'R2': r2_score(y_test_perda, y_pred_gb_perda),
            'RMSE': np.sqrt(mean_squared_error(y_test_perda, y_pred_gb_perda)),
            'MAE': mean_absolute_error(y_test_perda, y_pred_gb_perda)
        }
        print(f"Modelo de Perda de Massa (Mp) - GradientBoosting (Best Params: {model_results['mass_loss']['GradientBoosting']['Best_Params']}) - R²: {model_results['mass_loss']['GradientBoosting']['R2']:.4f}, RMSE: {model_results['mass_loss']['GradientBoosting']['RMSE']:.4f}, MAE: {model_results['mass_loss']['GradientBoosting']['MAE']:.4f}") # [cite: 29]

        # Select best model for mass loss
        best_perda_model_name = max(model_results['mass_loss'], key=lambda k: model_results['mass_loss'][k]['R2'] if 'R2' in model_results['mass_loss'][k] else -np.inf)
        if best_perda_model_name == 'LinearRegression': best_models['mass_loss'] = model_lr_perda
        elif best_perda_model_name == 'RandomForest': best_models['mass_loss'] = model_rf_perda
        else: best_models['mass_loss'] = model_gb_perda

        # Feature Importance for the best ensemble model (if applicable)
        if hasattr(best_models['mass_loss'], 'feature_importances_'):
            importances_perda = best_models['mass_loss'].feature_importances_
            feature_names_perda = X_perda.columns
            feature_importance_df_perda = pd.DataFrame({'Feature': feature_names_perda, 'Importance': importances_perda}).sort_values(by='Importance', ascending=False)
            model_results['mass_loss']['Feature_Importance'] = feature_importance_df_perda.to_dict('records')

            plt.figure(figsize=(10, 6))
            sns.barplot(x='Importance', y='Feature', data=feature_importance_df_perda.head(10))
            plt.title(f'Top 10 Feature Importances - Perda de Massa ({best_perda_model_name})')
            plt.tight_layout()
            plt.savefig(os.path.join(reports_dir, 'feature_importance_perda_massa.png'))
            plt.close()

        # Real vs Predicted Plot for Mass Loss
        plt.figure(figsize=(8, 6))
        plt.scatter(y_test_perda, best_models['mass_loss'].predict(X_test_perda), alpha=0.6)
        plt.plot([y_test_perda.min(), y_test_perda.max()], [y_test_perda.min(), y_test_perda.max()], 'r--')
        plt.title(f'Real vs. Previsto - Perda de Massa ({best_perda_model_name})')
        plt.xlabel('Valor Real de Mp (%)')
        plt.ylabel('Valor Previsto de Mp (%)')
        plt.savefig(os.path.join(reports_dir, 'real_vs_predicted_perda_massa.png'))
        plt.close()

    return best_models.get('absorption'), best_models.get('mass_loss'), model_results, X_abs, X_perda
def run_simulations(model_abs, model_perda, X_template_abs, X_template_perda, reports_dir):
    """Executa cenários de simulação e gera gráficos."""
    print("\n--- Running Simulation Scenarios ---")
    simulation_results = []
    simulation_plots_data_cw = {}
    simulation_plots_data_mp = {}

    # Get a mean/mode template for features, crucial for building scenarios
    base_features_abs = X_template_abs.mean().to_dict()
    base_features_perda = X_template_perda.mean().to_dict()

    # Ensure binary one-hot encoded features are set to 0 or 1, not floats
    for k in base_features_abs:
        if k.startswith(('Tipo_Liquido_', 'metodo_')) and 'Tipo_Liquido_SS_0.9%' in X_template_abs.columns: # Assume SS is the base (0)
            base_features_abs[k] = 0.0 # Default to 0
        if k.startswith('metodo_') and 'metodo_M1' in X_template_abs.columns: # Assume M1 is a base (0)
            base_features_abs[k] = 0.0
    # Specific categorical features (from obtaining_categorical_features)
    if 'Passagem_Agua_Reator' in base_features_abs: base_features_abs['Passagem_Agua_Reator'] = 0.0
    if 'Adicao_Metodo_B' in base_features_abs: base_features_abs['Adicao_Metodo_B'] = 0.0
    if 'Adicao_Metodo_C' in base_features_abs: base_features_abs['Adicao_Metodo_C'] = 0.0

    # Ensure a default liquid type (e.g., Agua if not explicitly set) for scenarios
    # This might require checking actual column names generated by one-hot encoding
    if 'Tipo_Liquido_Agua' in base_features_abs: base_features_abs['Tipo_Liquido_Agua'] = 1.0 # Set Agua as default
    if 'Tipo_Liquido_FCS' in base_features_abs: base_features_abs['Tipo_Liquido_FCS'] = 0.0
    if 'Tipo_Liquido_SS_0.9%' in base_features_abs: base_features_abs['Tipo_Liquido_SS_0.9%'] = 0.0


    for k in base_features_perda:
        if k.startswith(('Tipo_Liquido_', 'metodo_')) and 'Tipo_Liquido_SS_0.9%' in X_template_perda.columns:
            base_features_perda[k] = 0.0
        if k.startswith('metodo_') and 'metodo_M1' in X_template_perda.columns:
            base_features_perda[k] = 0.0
    if 'Passagem_Agua_Reator' in base_features_perda: base_features_perda['Passagem_Agua_Reator'] = 0.0
    if 'Adicao_Metodo_B' in base_features_perda: base_features_perda['Adicao_Metodo_B'] = 0.0
    if 'Adicao_Metodo_C' in base_features_perda: base_features_perda['Adicao_Metodo_C'] = 0.0
    if 'Tipo_Liquido_Agua' in base_features_perda: base_features_perda['Tipo_Liquido_Agua'] = 1.0
    if 'Tipo_Liquido_FCS' in base_features_perda: base_features_perda['Tipo_Liquido_FCS'] = 0.0
    if 'Tipo_Liquido_SS_0.9%' in base_features_perda: base_features_perda['Tipo_Liquido_SS_0.9%'] = 0.0


    # Define diverse scenarios (at least 10)
    scenarios_definitions = [
        # Promising Scenarios for Cw (high Cw) / Mp (low Mp) based on common understanding
        {'name': 'Cenário 1: Alta Absorção (FCS, Alta Conc. Quitosana, Tempo Med.)', 'Tempo_h': 24, 'Tipo_Liquido_FCS': 1, 'Concentracao_Quitosana_pct': 70, 'Vazao_mL_h': 100, 'massa_seca_inicial':0.05, 'peso_seco_inicial':0.05},
        {'name': 'Cenário 2: Baixa Perda (Água, Secagem Ambiente, Baixa Vazão)', 'Tempo_h': 48, 'Tipo_Liquido_Agua': 1, 'Secagem_Temperatura_C': 25, 'Vazao_mL_h': 50, 'massa_seca_inicial':0.05, 'peso_seco_inicial':0.05},
        {'name': 'Cenário 3: Bom Balanço (SS, Conc. Média, Agitação Prolongada)', 'Tempo_h': 16, 'Tipo_Liquido_SS_0.9%': 1, 'Concentracao_Quitosana_pct': 50, 'Tempo_Agitacao_h': 12, 'massa_seca_inicial':0.05, 'peso_seco_inicial':0.05},
        # Non-promising Scenarios
        {'name': 'Cenário 4: Baixa Absorção (FCS, Baixa Conc. Quitosana, Curto Tempo)', 'Tempo_h': 8, 'Tipo_Liquido_FCS': 1, 'Concentracao_Quitosana_pct': 10, 'massa_seca_inicial':0.05, 'peso_seco_inicial':0.05},
        {'name': 'Cenário 5: Alta Perda (Água, Secagem Alta, Tempo Longo)', 'Tempo_h': 72, 'Tipo_Liquido_Agua': 1, 'Secagem_Temperatura_C': 80, 'massa_seca_inicial':0.05, 'peso_seco_inicial':0.05},
        # Other diverse scenarios
        {'name': 'Cenário 6: Otimizado para Baixo pH (FCS, pH Ácido)', 'Tempo_h': 24, 'Tipo_Liquido_FCS': 1, 'pH': 4.0, 'Concentracao_Quitosana_pct': 60, 'massa_seca_inicial':0.05, 'peso_seco_inicial':0.05},
        {'name': 'Cenário 7: Alta Pressão (SS, Boa Vazão)', 'Tempo_h': 48, 'Tipo_Liquido_SS_0.9%': 1, 'Pressao_kPa': 500, 'Vazao_mL_h': 300, 'massa_seca_inicial':0.05, 'peso_seco_inicial':0.05},
        {'name': 'Cenário 8: Agitação Rápida (Água)', 'Tempo_h': 12, 'Tipo_Liquido_Agua': 1, 'Velocidade_Agitacao_rpm': 1000, 'massa_seca_inicial':0.05, 'peso_seco_inicial':0.05},
        {'name': 'Cenário 9: Passagem Água Reator (FCS, Média Conc.)', 'Tempo_h': 24, 'Tipo_Liquido_FCS': 1, 'Passagem_Agua_Reator': 1, 'Concentracao_Quitosana_pct': 45, 'massa_seca_inicial':0.05, 'peso_seco_inicial':0.05},
        {'name': 'Cenário 10: Método de Adição Específico (Água, Adição B)', 'Tempo_h': 36, 'Tipo_Liquido_Agua': 1, 'Adicao_Metodo_B': 1, 'massa_seca_inicial':0.05, 'peso_seco_inicial':0.05},
        {'name': 'Cenário 11: Combinação Extrema (FCS, Alta Temp, Baixo pH)', 'Tempo_h': 24, 'Tipo_Liquido_FCS': 1, 'Secagem_Temperatura_C': 90, 'pH': 3.0, 'massa_seca_inicial':0.05, 'peso_seco_inicial':0.05},
    ]

    for scenario_def in scenarios_definitions:
        scenario_name = scenario_def['name']

        # Create input features for absorption model
        current_features_abs = base_features_abs.copy()
        for key, value in scenario_def.items():
            if key != 'name':
                if key.startswith('Tipo_Liquido_'): # Handle one-hot encoding for liquid type
                    for tl_col in [c for c in X_template_abs.columns if c.startswith('Tipo_Liquido_')]:
                        current_features_abs[tl_col] = 0.0
                    if key in current_features_abs: current_features_abs[key] = 1.0
                elif key.startswith('Adicao_Metodo_'): # Handle one-hot encoding for Adicao_Metodo
                    for am_col in [c for c in X_template_abs.columns if c.startswith('Adicao_Metodo_')]:
                        current_features_abs[am_col] = 0.0
                    if key in current_features_abs: current_features_abs[key] = 1.0
                elif key in current_features_abs: # For other direct features
                    current_features_abs[key] = value

        # Ensure all columns expected by the model are present, fill with mean if not set
        input_df_abs = pd.DataFrame([current_features_abs], columns=X_template_abs.columns)
        predicted_cw = model_abs.predict(input_df_abs)[0]

        # Create input features for mass loss model
        current_features_perda = base_features_perda.copy()
        for key, value in scenario_def.items():
            if key != 'name':
                if key.startswith('Tipo_Liquido_'):
                    for tl_col in [c for c in X_template_perda.columns if c.startswith('Tipo_Liquido_')]:
                        current_features_perda[tl_col] = 0.0
                    if key in current_features_perda: current_features_perda[key] = 1.0
                elif key.startswith('Adicao_Metodo_'):
                    for am_col in [c for c in X_template_perda.columns if c.startswith('Adicao_Metodo_')]:
                        current_features_perda[am_col] = 0.0
                    if key in current_features_perda: current_features_perda[key] = 1.0
                elif key in current_features_perda:
                    current_features_perda[key] = value

        input_df_perda = pd.DataFrame([current_features_perda], columns=X_template_perda.columns)
        predicted_mp = model_perda.predict(input_df_perda)[0]

        simulation_results.append({
            'Scenario': scenario_name,
            'Input_Params': scenario_def, # Store the defined params for report
            'Predicted_Cw': predicted_cw,
            'Predicted_Mp': predicted_mp
        })
        print(f"Scenario: {scenario_name}, Predicted Cw: {predicted_cw:.4f}, Predicted Mp: {predicted_mp:.4f}")

    # Plotting simulation curves (e.g., Cw/Mp over time for selected scenarios)
    print("\nPlotting Simulation Curves...")
    time_points = np.linspace(1, 72, 15).round().astype(int) # More points for smoother curves

    # Select a couple of scenarios to plot curves for
    # Plotting scenarios 1, 2, 4 (promising and non-promising examples)
    plot_scenarios_indices = [0, 1, 3]

    for idx in plot_scenarios_indices:
        scenario_def = scenarios_definitions[idx]
        scenario_name = scenario_def['name']

        # Simulate Cw over time
        cw_over_time = []
        for t in time_points:
            temp_features_abs = base_features_abs.copy()
            for key, value in scenario_def.items():
                if key != 'name':
                    if key.startswith('Tipo_Liquido_'):
                        for tl_col in [c for c in X_template_abs.columns if c.startswith('Tipo_Liquido_')]:
                            temp_features_abs[tl_col] = 0.0
                        if key in temp_features_abs: temp_features_abs[key] = 1.0
                    elif key.startswith('Adicao_Metodo_'):
                        for am_col in [c for c in X_template_abs.columns if c.startswith('Adicao_Metodo_')]:
                            temp_features_abs[am_col] = 0.0
                        if key in temp_features_abs: temp_features_abs[key] = 1.0
                    elif key in temp_features_abs:
                        temp_features_abs[key] = value

            temp_features_abs['Tempo_h'] = t
            input_df_time_abs = pd.DataFrame([temp_features_abs], columns=X_template_abs.columns)
            cw_over_time.append(model_abs.predict(input_df_time_abs)[0])
        simulation_plots_data_cw[scenario_name] = {'Time': time_points, 'Cw': cw_over_time}

        # Simulate Mp over time
        mp_over_time = []
        for t in time_points:
            temp_features_perda = base_features_perda.copy()
            for key, value in scenario_def.items():
                if key != 'name':
                    if key.startswith('Tipo_Liquido_'):
                        for tl_col in [c for c in X_template_perda.columns if c.startswith('Tipo_Liquido_')]:
                            temp_features_perda[tl_col] = 0.0
                        if key in temp_features_perda: temp_features_perda[key] = 1.0
                    elif key.startswith('Adicao_Metodo_'):
                        for am_col in [c for c in X_template_perda.columns if c.startswith('Adicao_Metodo_')]:
                            temp_features_perda[am_col] = 0.0
                        if key in temp_features_perda: temp_features_perda[key] = 1.0
                    elif key in temp_features_perda:
                        temp_features_perda[key] = value

            temp_features_perda['Tempo_h'] = t
            input_df_time_perda = pd.DataFrame([temp_features_perda], columns=X_template_perda.columns)
            mp_over_time.append(model_perda.predict(input_df_time_perda)[0])
        simulation_plots_data_mp[scenario_name] = {'Time': time_points, 'Mp': mp_over_time}

    # Plot Cw simulation curves
    plt.figure(figsize=(10, 6))
    for name, data in simulation_plots_data_cw.items():
        plt.plot(data['Time'], data['Cw'], marker='o', linestyle='--', label=name)
    plt.title('Simulação de Cw ao Longo do Tempo para Cenários Selecionados')
    plt.xlabel('Tempo (h)')
    plt.ylabel('Predicted Cw (g/g)')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(reports_dir, 'simulated_cw_curves.png'))
    plt.close()

    # Plot Mp simulation curves
    plt.figure(figsize=(10, 6))
    for name, data in simulation_plots_data_mp.items():
        plt.plot(data['Time'], data['Mp'], marker='o', linestyle='--', label=name)
    plt.title('Simulação de Mp ao Longo do Tempo para Cenários Selecionados')
    plt.xlabel('Tempo (h)')
    plt.ylabel('Predicted Mp (%)')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(reports_dir, 'simulated_mp_curves.png'))
    plt.close()

    return simulation_results
def optimize_biopolymer_properties(model_abs, model_perda, X_template_abs, X_template_perda):
    """Otimiza as propriedades dos biopolímeros para atingir Cw desejado."""
    print("\n--- Otimizando Propriedades de Biopolímeros ---") # [cite: 29]

    if model_abs is None or X_template_abs.empty:
        print("Modelo de absorção ou template de features vazio. Otimização não pode ser realizada.")
        return None, None, None, "Modelos ou dados insuficientes."

    # Define the specific continuous features to optimize (from obtaining features)
    continuous_optimization_features = ['Concentracao_Quitosana_pct', 'Vazao_mL_h']

    # Check if these features exist in the template
    for feat in continuous_optimization_features:
        if feat not in X_template_abs.columns:
            print(f"Erro: Feature de otimização '{feat}' não encontrada nas colunas do template do modelo. Verifique o pré-processamento.")
            return None, None, None, "Feature de otimização não encontrada."

    # Define fixed parameters for the optimization context
    # Objective: Maximize CW_gg_Unificado in 24h for Absocao_FCS
    fixed_params_abs = X_template_abs.mean().to_dict()
    fixed_params_perda = X_template_perda.mean().to_dict()

    # Set specific fixed values for the optimization problem
    fixed_params_abs['Tempo_h'] = 24.0 # Optimize at 24 hours
    fixed_params_perda['Tempo_h'] = 24.0

    # Set liquid type to FCS (assuming one-hot encoded columns exist)
    for col in [c for c in X_template_abs.columns if c.startswith('Tipo_Liquido_')]:
        fixed_params_abs[col] = 0.0
    if 'Tipo_Liquido_FCS' in X_template_abs.columns:
        fixed_params_abs['Tipo_Liquido_FCS'] = 1.0 # Set FCS as active liquid type

    for col in [c for c in X_template_perda.columns if c.startswith('Tipo_Liquido_')]:
        fixed_params_perda[col] = 0.0
    if 'Tipo_Liquido_FCS' in X_template_perda.columns:
        fixed_params_perda['Tipo_Liquido_FCS'] = 1.0

    # Ensure other categorical obtaining features are set to a default (e.g., 0 for one-hot encoded ones)
    for col in [c for c in X_template_abs.columns if c.startswith('Adicao_Metodo_') or c.startswith('Passagem_Agua_Reator_')]:
        fixed_params_abs[col] = 0.0
    for col in [c for c in X_template_perda.columns if c.startswith('Adicao_Metodo_') or c.startswith('Passagem_Agua_Reator_')]:
        fixed_params_perda[col] = 0.0


    # Objective: Maximize Cw, so we minimize -Cw
    def objective_function(opt_params_values):
        current_features_abs = fixed_params_abs.copy()
        for i, feat_name in enumerate(continuous_optimization_features):
            current_features_abs[feat_name] = opt_params_values[i]

        # Convert to DataFrame, ensuring column order matches model's training data [cite: 31, 32]
        input_df_abs = pd.DataFrame([current_features_abs], columns=X_template_abs.columns)

        predicted_cw = model_abs.predict(input_df_abs)[0] # [cite: 32]

        return -predicted_cw # Minimize the negative of CW to maximize CW

    # Define bounds for the continuous optimization features
    bounds_opt = []
    for feat in continuous_optimization_features:
        # Get min/max from the actual data for realistic bounds
        min_val = X_template_abs[feat].min()
        max_val = X_template_abs[feat].max()
        bounds_opt.append((min_val, max_val)) # [cite: 33]

    # Initial guess: mean values of the optimized features from the template [cite: 34]
    initial_guess_opt = [X_template_abs[feat].mean() for feat in continuous_optimization_features]

    # Perform optimization
    result = minimize(objective_function, initial_guess_opt, bounds=bounds_opt, method='L-BFGS-B') # [cite: 34]

    optimized_values = {}
    for i, feat_name in enumerate(continuous_optimization_features):
        optimized_values[feat_name] = result.x[i]

    # Reconstruct the full feature set with optimized values for final prediction display
    final_optimized_features_abs = fixed_params_abs.copy()
    for feat_name, val in optimized_values.items():
        final_optimized_features_abs[feat_name] = val

    final_optimized_features_perda = fixed_params_perda.copy()
    for feat_name, val in optimized_values.items():
        final_optimized_features_perda[feat_name] = val

    optimized_df_abs = pd.DataFrame([final_optimized_features_abs], columns=X_template_abs.columns)
    optimized_df_perda = pd.DataFrame([final_optimized_features_perda], columns=X_template_perda.columns)

    predicted_cw_optimized = model_abs.predict(optimized_df_abs)[0] # [cite: 34]
    predicted_mp_optimized = model_perda.predict(optimized_df_perda)[0] # [cite: 35]

    print(f"Status da Otimização: {result.message}") # [cite: 34]
    print(f"Valor mínimo da função objetivo (-Cw): {result.fun:.4f}") # [cite: 34]
    print(f"Parâmetros otimizados: {optimized_values}") # [cite: 34]
    print(f"Cw previsto com parâmetros otimizados: {predicted_cw_optimized:.4f}") # [cite: 35]
    print(f"Mp previsto com parâmetros otimizados: {predicted_mp_optimized:.4f}") # [cite: 35]

    # For categorical variables, conceptually choose the best one from a fixed set
    # (Here, we fix Tipo_Liquido to FCS for the optimization problem)
    # If there were other categorical variables to "optimize", you'd test each and compare.
    best_categorical_combination_str = "Tipo_Liquido: FCS (fixo para este objetivo)"
    if 'Adicao_Metodo_B' in X_template_abs.columns:
        best_categorical_combination_str += ", Adicao_Metodo: (depende do teste)"

    return optimized_values, predicted_cw_optimized, predicted_mp_optimized, best_categorical_combination_str
def generate_detailed_report_markdown(data_collector, reports_dir):
    """Gera o relatório detalhado em formato Markdown."""
    report_content = []

    report_content.append("# Relatório Detalhado de Análise e Otimização do Comportamento de Biopolímeros (Quitosana e Alginato) Utilizando Data Science\n\n") # [cite: 152]

    report_content.append("## Sumário Executivo\n\n") # [cite: 153]
    report_content.append("Este relatório detalha a análise, modelagem preditiva e otimização do comportamento de biopolímeros, especificamente quitosana e alginato, com foco em suas propriedades de absorção de líquidos (Cw) e perda de massa (Mp). Utilizando técnicas de Data Science, o projeto visa fornecer insights estratégicos para aplicações em saúde e indústria. Os modelos de Machine Learning demonstraram alta capacidade preditiva, e a otimização identificou condições ideais de processo para atingir propriedades desejadas dos biopolímeros, **com um foco significativo no impacto das características de obtenção**.\n\n")

    report_content.append("---")

    report_content.append("## 1. Introdução\n\n") # [cite: 154]
    report_content.append("A pesquisa e o desenvolvimento de biopolímeros são cruciais para diversas aplicações, desde biomateriais e engenharia de tecidos até a indústria de alimentos e embalagens. Compreender e otimizar suas propriedades, como a capacidade de absorção de líquidos e a taxa de degradação (perda de massa), é fundamental para garantir seu desempenho e segurança. Este projeto utiliza abordagens de Data Science, incluindo análise exploratória de dados, modelagem preditiva com Machine Learning e técnicas de otimização, para desvendar as relações complexas entre as características de obtenção dos biopolímeros e seu comportamento funcional ao longo do tempo. O objetivo principal é desenvolver um sistema que permita prever e otimizar essas propriedades, apoiando a tomada de decisão em pesquisa e aplicações industriais.\n\n") # [cite: 154]

    report_content.append("---")

    report_content.append("## 2. Metodologia de Dados e Preparação (Fase 1)\n\n") # [cite: 155]
    report_content.append("### Detalhes dos Arquivos de Entrada\n\n") # [cite: 156]
    report_content.append("Os dados para esta análise foram obtidos a partir de sete arquivos CSV, cada um contendo informações específicas sobre as propriedades dos biopolímeros:\n\n")
    report_content.append("- **Absorção de Líquidos**: `Absorcao_FCS.csv`, `Absorcao_Agua.csv`, `Absorcao_SS_0,9%.csv` – Registram a capacidade de absorção de diferentes líquidos (Soro Fisiológico (FCS), Água, e Solução Salina 0.9% (SS_0.9%)) em diferentes pontos de tempo.\n") # [cite: 64, 65, 66]
    report_content.append("- **Perda de Massa**: `perda_massa_Agua.csv`, `Perda_massa_FCS.csv`, `perda_massa_SS_0.9%.csv` – Detalham a perda de massa dos biopolímeros quando em contato com os respectivos líquidos ao longo do tempo.\n") # [cite: 68, 69, 70]
    report_content.append("- **Metodologias de Obtenção**: `metodos_obtencao_biopolimeros.csv` – Contém características detalhadas do processo de obtenção de cada biopolímero, identificadas por um `ID_Metodo` (M1 a M66). Estas características incluem, mas não se limitam a, `Concentracao_Quitosana_pct`, `Vazao_mL_h`, `Secagem_Temperatura_C`, `pH`, `Tempo_Agitacao_h`, `Velocidade_Agitacao_rpm`, `Pressao_kPa`, `Passagem_Agua_Reator`, e `Adicao_Metodo`.\n\n") # [cite: 71, 72]

    report_content.append("### Limpeza e Consistência de Dados\n\n") # [cite: 159]
    report_content.append("As colunas 'Unnamed' foram removidas, duplicatas foram tratadas e valores ausentes foram preenchidos com a média (para numéricos) ou moda (para categóricos). Estratégias de preenchimento específicas foram aplicadas para `Vazao_mL_h` (preenchido com 0) e `Secagem_Temperatura_C` (preenchido com 25°C para temperatura ambiente), garantindo a consistência física dos dados e alinhamento com os requisitos experimentais.\n\n")

    report_content.append("### Consolidação e Transformação (Formato Largo para Longo)\n\n") # [cite: 157]
    report_content.append("Os dados de absorção e perda de massa foram consolidados em DataFrames únicos, com a adição da coluna `Tipo_Liquido` baseada no nome do arquivo original. Em seguida, foram transformados do formato 'largo' para 'longo' utilizando a operação `melt` do Pandas, criando colunas `Tempo_h`, `Massa_Umida_Final_Unificado` (para absorção) e `Peso_Seco_Final_Unificado` (para perda de massa), juntamente com suas respectivas propriedades (`CW_gg_Unificado` e `Mp_Percentual_Unificado`). Esta transformação é crucial para facilitar a análise temporal e a modelagem preditiva ao padronizar a representação das medições ao longo do tempo.\n\n") # [cite: 157]

    report_content.append("### Integração com Métodos de Obtenção\n\n") # [cite: 158]
    report_content.append("Finalmente, os DataFrames consolidados de absorção e perda de massa foram mesclados com o DataFrame de métodos de obtenção (`df_metodos_obtencao_biopolimeros`), utilizando as colunas `metodo` (do df de absorção/perda) e `ID_Metodo` (do df de métodos) como chaves. Esta etapa enriqueceu os dados com informações detalhadas sobre as condições de fabricação dos biopolímeros, permitindo uma análise mais profunda do impacto dessas condições em suas propriedades.\n\n") # [cite: 158]

    report_content.append("### Inspeção dos DataFrames Finais Consolidados\n\n") # [cite: 160]
    report_content.append("#### DataFrame de Absorção Integrado (`df_absorcao_integrado`)\n")
    report_content.append("```\n")
    report_content.append(data_collector['consolidated_data_info']['absorcao_info'])
    report_content.append("```\n")
    report_content.append("Primeiras 5 linhas:\n")
    report_content.append(data_collector['consolidated_data_info']['absorcao_head'])
    report_content.append("\nEstatísticas Descritivas:\n")
    report_content.append(data_collector['consolidated_data_info']['absorcao_describe'])
    report_content.append("\nNaNs após integração:\n")
    report_content.append(data_collector['consolidated_data_info']['absorcao_nan'])
    report_content.append("\n")

    report_content.append("#### DataFrame de Perda de Massa Integrado (`df_perda_integrado`)\n")
    report_content.append("```\n")
    report_content.append(data_collector['consolidated_data_info']['perda_info'])
    report_content.append("```\n")
    report_content.append("Primeiras 5 linhas:\n")
    report_content.append(data_collector['consolidated_data_info']['perda_head'])
    report_content.append("\nEstatísticas Descritivas:\n")
    report_content.append(data_collector['consolidated_data_info']['perda_describe'])
    report_content.append("\nNaNs após integração:\n")
    report_content.append(data_collector['consolidated_data_info']['perda_nan'])
    report_content.append("\n")

    report_content.append("---")

    report_content.append("## 3. Análise Exploratória de Dados (EDA)\n\n") # [cite: 162]
    report_content.append("A Análise Exploratória de Dados (EDA) foi conduzida para identificar padrões, relações e insights relevantes no comportamento dos biopolímeros e o impacto de suas características de obtenção. Foram gerados diversos gráficos e estatísticas:\n\n") # [cite: 163]

    report_content.append("### Distribuição das Variáveis Chave\n")
    report_content.append("Os histogramas de `CW_gg_Unificado` e `Mp_Percentual_Unificado` mostram a distribuição das propriedades de interesse. Além disso, as distribuições de variáveis numéricas de obtenção como `Concentracao_Quitosana_pct`, `Vazao_mL_h` e `Secagem_Temperatura_C` foram analisadas, revelando a gama de condições experimentais cobertas pelos dados.\n\n")
    report_content.append("![Distribuição de Cw (Absorção)](distribuicao_cw_absorcao.png)\n\n") # [cite: 49]
    report_content.append("![Distribuição de Mp (Perda de Massa)](distribuicao_mp_perda_massa.png)\n\n") # [cite: 49]
    report_content.append("![Distribuição de Concentracao_Quitosana_pct](hist_concentracao_quitosana_pct.png)\n\n")
    report_content.append("![Distribuição de Vazao_mL_h](hist_vazao_ml_h.png)\n\n")
    report_content.append("![Distribuição de Secagem_Temperatura_C](hist_secagem_temperatura_c.png)\n\n")


    report_content.append("### Relação entre Tempo e Absorção/Perda de Massa por Tipo de Líquido\n")
    report_content.append("Os gráficos de linha de `CW_gg_Unificado` e `Mp_Percentual_Unificado` ao longo do `Tempo_h`, agrupados por `Tipo_Liquido`, demonstram como as propriedades variam com a exposição a diferentes meios. Por exemplo, a absorção em FCS pode ser consistentemente maior, enquanto a perda de massa na água pode ser mais acentuada após um certo período, indicando diferenças significativas na interação biopolímero-líquido.\n\n") # [cite: 163]
    report_content.append("![Cw (Absorção) ao longo do Tempo por Tipo de Líquido](cw_tempo_tipo_liquido.png)\n\n") # [cite: 49]
    report_content.append("![Mp (Perda de Massa) ao longo do Tempo por Tipo de Líquido](mp_tempo_tipo_liquido.png)\n\n") # [cite: 49]

    report_content.append("### Comparação de Absorção/Perda de Massa por Método de Obtenção e Outras Características Categóricas\n")
    report_content.append("Os box plots de `CW_gg_Unificado` e `Mp_Percentual_Unificado` agrupados por `metodo` (método de obtenção) e outras **features categóricas de obtenção** (como `Adicao_Metodo` e `Passagem_Agua_Reator`) revelam a variabilidade das propriedades em função do processo de fabricação. Certos métodos ou tipos de adição podem resultar em biopolímeros com maior ou menor capacidade de absorção ou perda de massa, evidenciando a influência direta das condições de obtenção.\n\n") # [cite: 163]
    report_content.append("![Cw (Absorção) por Método de Obtenção](cw_metodo_obtencao.png)\n\n") # [cite: 49]
    report_content.append("![Mp (Perda de Massa) por Método de Obtenção](mp_metodo_obtencao.png)\n\n") # [cite: 49]
    report_content.append("![Cw (Absorção) por Adicao_Metodo](cw_boxplot_adicao_metodo.png)\n\n")
    report_content.append("![Mp (Perda de Massa) por Adicao_Metodo](mp_boxplot_adicao_metodo.png)\n\n")
    report_content.append("![Cw (Absorção) por Passagem_Agua_Reator](cw_boxplot_passagem_agua_reator.png)\n\n")
    report_content.append("![Mp (Perda de Massa) por Passagem_Agua_Reator](mp_boxplot_passagem_agua_reator.png)\n\n")

    report_content.append("### Correlação entre Variáveis Numéricas\n")
    report_content.append("Os scatter plots de `massa_seca_inicial` vs. `Cw` e `peso_seco_inicial` vs. `Mp` indicam a relação entre a massa inicial da amostra e as propriedades finais. O **heatmap de correlação** oferece uma visão abrangente das inter-relações entre todas as variáveis numéricas, incluindo as **novas features de obtenção**. Observa-se a existência de correlações significativas entre as propriedades do biopolímero e as condições de processo, como a `Concentracao_Quitosana_pct` e a `Vazao_mL_h`, sublinhando a importância dessas variáveis no comportamento final.\n\n") # [cite: 163]
    report_content.append("![Massa Seca Inicial vs Cw (Absorção)](massa_seca_inicial_vs_cw.png)\n\n") # [cite: 49]
    report_content.append("![Peso Seco Inicial vs Mp (Perda de Massa)](peso_seco_inicial_vs_mp.png)\n\n") # [cite: 49]
    report_content.append("![Heatmap de Correlação - Absorção](heatmap_correlacao_absorcao.png)\n\n")
    report_content.append("![Heatmap de Correlação - Perda de Massa](heatmap_correlacao_perda_massa.png)\n\n")

    report_content.append("---")

    report_content.append("## 4. Modelagem Preditiva do Comportamento de Biopolímeros (Fase 2)\n\n") # [cite: 165]
    report_content.append("Para prever o comportamento de absorção (Cw) e perda de massa (Mp), foram treinados e avaliados três modelos de regressão: Regressão Linear, Random Forest Regressor e Gradient Boosting Regressor. As features de entrada para os modelos incluíram o `Tempo_h`, `Tipo_Liquido`, `massa_seca_inicial` (ou `peso_seco_inicial`), e **TODAS as características de obtenção** presentes no dataset `metodos_obtencao_biopolimeros.csv` (e.g., Concentracao_Quitosana_pct, Vazao_mL_h, Secagem_Temperatura_C, pH, Tempo_Agitacao_h, Velocidade_Agitacao_rpm, Pressao_kPa, Passagem_Agua_Reator, Adicao_Metodo). Foi realizado um ajuste básico de hiperparâmetros (GridSearchCV simples) para os modelos de ensemble, otimizando seu desempenho.\n\n") # [cite: 166]

    report_content.append("### Resultados da Avaliação do Modelo\n\n") # [cite: 168]
    report_content.append("As métricas de desempenho (R², RMSE, MAE) foram calculadas para cada modelo e cada target, conforme a tabela a seguir:\n\n") # [cite: 168]
    report_content.append("| Modelo               | Alvo     | R²      | RMSE    | MAE     |\n")
    report_content.append("|----------------------|----------|---------|---------|---------|\n")
    if 'absorption' in data_collector['model_evaluation']:
        for model_name, metrics in data_collector['model_evaluation']['absorption'].items():
            if model_name not in ['Feature_Importance']:
                report_content.append(f"| {model_name:<20} | Absorção | {metrics['R2']:.4f}  | {metrics['RMSE']:.4f}  | {metrics['MAE']:.4f}  |\n")
    if 'mass_loss' in data_collector['model_evaluation']:
        for model_name, metrics in data_collector['model_evaluation']['mass_loss'].items():
            if model_name not in ['Feature_Importance']:
                report_content.append(f"| {model_name:<20} | Perda    | {metrics['R2']:.4f} | {metrics['RMSE']:.4f} | {metrics['MAE']:.4f} |\n")
    report_content.append("\n")

    report_content.append("Os modelos de ensemble (Random Forest e Gradient Boosting) geralmente apresentaram desempenho superior em comparação com a Regressão Linear, indicando a natureza não-linear das relações nos dados e a capacidade de capturar interações complexas. O Random Forest Regressor foi escolhido como o modelo principal para as fases subsequentes devido ao seu bom balanço entre desempenho e interpretabilidade.\n\n") # [cite: 169]

    report_content.append("### Análise da Importância das Features\n\n") # [cite: 170]
    report_content.append("A importância das features foi avaliada para os melhores modelos de ensemble, revelando o impacto quantitativo das variáveis de entrada no comportamento dos biopolímeros. As **características de obtenção** mostraram-se cruciais para a previsão, destacando a necessidade de otimizar esses parâmetros de processo, como `Concentracao_Quitosana_pct` e `Vazao_mL_h` que frequentemente aparecem entre as features mais importantes.\n\n") # [cite: 170]

    if data_collector['feature_importance_abs']:
        report_content.append("#### Importância das Features para Absorção\n")
        report_content.append("| Feature | Importância |\n")
        report_content.append("|---------|-------------|\n")
        for item in data_collector['feature_importance_abs']:
            report_content.append(f"| {item['Feature']} | {item['Importance']:.4f} |\n")
        report_content.append("\n")
        report_content.append("![Feature Importance - Absorção](feature_importance_absorption.png)\n\n")

    if data_collector['feature_importance_perda']:
        report_content.append("#### Importância das Features para Perda de Massa\n")
        report_content.append("| Feature | Importância |\n")
        report_content.append("|---------|-------------|\n")
        for item in data_collector['feature_importance_perda']:
            report_content.append(f"| {item['Feature']} | {item['Importance']:.4f} |\n")
        report_content.append("\n")
        report_content.append("![Feature Importance - Perda de Massa](feature_importance_perda_massa.png)\n\n")

    report_content.append("### Gráficos de Valores Reais vs. Previstos\n\n") # [cite: 171]
    report_content.append("Os gráficos de dispersão a seguir comparam os valores reais de Cw e Mp com os valores previstos pelos modelos, demonstrando a acurácia das previsões e a capacidade dos modelos em generalizar para dados não vistos. Uma boa concentração de pontos ao redor da linha diagonal indica alta precisão do modelo.\n\n") # [cite: 171]
    report_content.append("![Real vs. Previsto - Absorção](real_vs_predicted_absorption.png)\n\n")
    report_content.append("![Real vs. Previsto - Perda de Massa](real_vs_predicted_perda_massa.png)\n\n")

    report_content.append("---")

    report_content.append("## 5. Simulação e Otimização para Aplicações (Fase 3)\n\n") # [cite: 172]
    report_content.append("### Simulação Detalhada de Formulações\n\n") # [cite: 173]
    report_content.append("Foram simuladas **onze (11) formulações** de biopolímeros, variando as condições de obtenção e os tempos de exposição aos líquidos, para entender seu impacto no Cw e Mp. A seguir, apresentamos estes cenários, incluindo exemplos de formulações promissoras e não promissoras, com seus respectivos parâmetros de entrada e saídas preditas. O objetivo é ilustrar como diferentes configurações de processo podem influenciar as propriedades finais do biopolímero, auxiliando na tomada de decisões estratégicas de desenvolvimento.\n\n") # [cite: 173]

    if data_collector['simulation_results']:
        report_content.append("| Cenário | Tempo (h) | Tipo Líquido | Conc. Quitosana (%) | Vazão (mL/h) | Secagem Temp. (°C) | pH | Tempo Agit. (h) | Vel. Agit. (rpm) | Pressão (kPa) | Passagem Água Reator | Adição Método | Cw Previsto (g/g) | Mp Previsto (%) |\n")
        report_content.append("|---------|-----------|--------------|---------------------|--------------|--------------------|----|-----------------|------------------|---------------|----------------------|---------------|-------------------|-----------------|\n")
        for res in data_collector['simulation_results']:
            params = res['Input_Params']
            # Dynamically extract liquid type from one-hot encoding for display in report
            liquid_type_display = 'N/A'
            for k in [c for c in params.keys() if c.startswith('Tipo_Liquido_')]:
                if params.get(k) == 1:
                    liquid_type_display = k.replace('Tipo_Liquido_', '')
                    break
            # Dynamically extract Adicao_Metodo
            adicao_metodo_display = 'N/A'
            for k in [c for c in params.keys() if c.startswith('Adicao_Metodo_')]:
                if params.get(k) == 1:
                    adicao_metodo_display = k.replace('Adicao_Metodo_', '')
                    break

            report_content.append(f"| {res['Scenario']} | {params.get('Tempo_h', 'N/A')} | {liquid_type_display} | {params.get('Concentracao_Quitosana_pct', 'N/A')} | {params.get('Vazao_mL_h', 'N/A')} | {params.get('Secagem_Temperatura_C', 'N/A')} | {params.get('pH', 'N/A')} | {params.get('Tempo_Agitacao_h', 'N/A')} | {params.get('Velocidade_Agitacao_rpm', 'N/A')} | {params.get('Pressao_kPa', 'N/A')} | {params.get('Passagem_Agua_Reator', 'N/A')} | {adicao_metodo_display} | {res['Predicted_Cw']:.4f} | {res['Predicted_Mp']:.4f} |\n")
        report_content.append("\n")

    report_content.append("As curvas a seguir demonstram o comportamento simulado de Cw e Mp ao longo do tempo para alguns dos cenários selecionados, oferecendo uma visão dinâmica de como as propriedades dos biopolímeros evoluem sob diferentes condições. Estas simulações ajudam a visualizar o impacto das variáveis de processo.\n\n") # [cite: 175]
    report_content.append("![Curva de Cw Simulada ao Longo do Tempo](simulated_cw_curves.png)\n\n")
    report_content.append("![Curva de Mp Simulada ao Longo do Tempo](simulated_mp_curves.png)\n\n")

    report_content.append("### Otimização Detalhada\n\n") # [cite: 176]
    report_content.append("O problema de otimização chave foi definido como **maximizar o `CW_gg_Unificado` em 24 horas para o tipo de líquido FCS (Soro Fisiológico)**. As variáveis de obtenção contínuas escolhidas para otimização foram `Concentracao_Quitosana_pct` e `Vazao_mL_h`. O modelo preditivo de Absorção (Cw) foi utilizado como função objetivo (minimizando o negativo de Cw para maximizá-lo), e a otimização foi realizada utilizando `scipy.optimize.minimize` com o método L-BFGS-B. Os limites para as variáveis de otimização foram definidos com base nos ranges dos dados existentes para garantir resultados realistas.\n\n") # [cite: 177, 178, 179]

    if data_collector['optimization_results'].get('optimized_values'):
        optimized_vals = data_collector['optimization_results']['optimized_values']
        predicted_cw_opt = data_collector['optimization_results']['predicted_cw']
        predicted_mp_opt = data_collector['optimization_results']['predicted_mp']
        best_cat_opt_str = data_collector['optimization_results']['best_categorical_combination']

        report_content.append(f"- **Variáveis Contínuas Otimizadas**: `Concentracao_Quitosana_pct` = **{optimized_vals.get('Concentracao_Quitosana_pct', 'N/A'):.2f}%**, `Vazao_mL_h` = **{optimized_vals.get('Vazao_mL_h', 'N/A'):.2f} mL/h**\n") # [cite: 179]
        report_content.append(f"- **Cw Máximo Previsto (Otimizado)**: **{predicted_cw_opt:.4f} g/g** (em 24h, com FCS)\n") # [cite: 179]
        report_content.append(f"- **Mp Previsto (com Parâmetros Otimizados para Cw)**: **{predicted_mp_opt:.4f} %**\n\n") # [cite: 179]
        report_content.append("Este resultado indica as condições de processo para fabricar biopolímeros com a máxima capacidade de absorção de Cw no tempo e meio especificados, maximizando sua aplicabilidade em cenários como biomateriais absorventes ou sistemas de entrega de medicamentos.\n\n")
    else:
        report_content.append("A otimização não foi realizada devido à falta de modelos preditivos treinados ou dados insuficientes.\n\n")

    report_content.append("#### Abordagem para Variáveis Categóricas na Otimização\n\n") # [cite: 180]
    report_content.append("Para variáveis categóricas de obtenção (ex: `Adicao_Metodo`, `Passagem_Agua_Reator`), a otimização direta com métodos de gradiente não é aplicável. A abordagem para incluir essas variáveis no processo de otimização seria:\n") # [cite: 180]
    report_content.append("- **Testar cada categoria individualmente**: Executar a otimização das variáveis contínuas para cada combinação possível das variáveis categóricas e, em seguida, comparar os resultados para identificar a combinação categórica que oferece o melhor desempenho para o objetivo definido. Por exemplo, otimizar `Concentracao_Quitosana_pct` e `Vazao_mL_h` para cada `Tipo_Liquido` ou `Adicao_Metodo` diferente.\n") # [cite: 180]
    report_content.append("- **Otimização Bayesiana ou Algoritmos Genéticos**: Para problemas mais complexos com muitas variáveis categóricas e contínuas, técnicas de otimização mais avançadas que podem lidar com diferentes tipos de variáveis de entrada de forma simultânea, como a otimização Bayesiana ou algoritmos genéticos, podem ser empregadas.\n\n") # [cite: 180]
    report_content.append(f"No presente estudo de otimização contínua focada em Cw, a combinação categórica principal considerada foi: **{best_cat_opt_str}**.\n\n") # [cite: 180]

    report_content.append("---")

    report_content.append("## 6. Insights e Recomendações Estratégicas (Fase 4)\n\n") # [cite: 181]
    report_content.append("A análise e otimização dos biopolímeros fornecem insights valiosos para P&D e tomada de decisão estratégica, permitindo uma abordagem baseada em dados para o design e a produção de materiais:\n\n") # [cite: 182]
    report_content.append("- **Impacto dos Métodos de Obtenção**: As características de obtenção, como a **concentração de quitosana**, **vazão de processo** e **temperatura de secagem**, têm um impacto significativo nas propriedades de absorção e perda de massa. A otimização desses parâmetros é crucial para o desenvolvimento de biopolímeros 'customizados' para aplicações específicas.\n") # [cite: 183]
    report_content.append("- **Seleção de Materiais e Meios**: A compreensão da interação entre os biopolímeros e os diferentes tipos de líquidos (FCS, Água, SS_0.9%) é fundamental. Para aplicações que exigem alta capacidade de absorção (ex: curativos, absorventes), biopolímeros que demonstram maior Cw em determinado meio são preferíveis. Para aplicações que demandam estabilidade a longo prazo (ex: embalagens, implantes), menor Mp é desejável.\n") # [cite: 183]
    report_content.append("- **Otimização de Processos de Fabricação**: Os modelos preditivos e a ferramenta de otimização podem ser utilizados para guiar o desenvolvimento de novos processos de fabricação de forma mais eficiente, reduzindo o tempo e custo de experimentação empírica intensiva, direcionando os esforços para as condições mais promissoras.\n") # [cite: 183]
    report_content.append("- **Recomendações Específicas**: Com base nos parâmetros otimizados para maximizar o Cw em FCS em 24h, recomenda-se que os processos de fabricação de biopolímeros considerem uma `Concentracao_Quitosana_pct` de aproximadamente **{optimized_vals.get('Concentracao_Quitosana_pct', 'N/A'):.2f}%** e uma `Vazao_mL_h` de **{optimized_vals.get('Vazao_mL_h', 'N/A'):.2f} mL/h**. Essas condições são projetadas para otimizar a performance de absorção, que é um fator crítico em aplicações biomédicas e pode levar a uma melhor performance do produto.\n\n") # [cite: 183]

    report_content.append("---")

    report_content.append("## 7. Conclusão\n\n") # [cite: 184]
    report_content.append("Este projeto demonstrou a eficácia da aplicação de Data Science na análise e otimização do comportamento de biopolímeros. A integração de dados de diversas fontes, a limpeza rigorosa, a análise exploratória detalhada e a modelagem preditiva avançada permitiram uma compreensão profunda das propriedades de absorção e perda de massa. A otimização, por sua vez, oferece uma ferramenta poderosa para projetar biopolímeros com características específicas, acelerando a inovação e o desenvolvimento de produtos.\n\n") # [cite: 184]
    report_content.append("### Limitações e Trabalhos Futuros\n\n") # [cite: 184]
    report_content.append("As principais limitações incluem a necessidade de mais dados para refinar os modelos e explorar interações mais complexas entre as features, além da validação experimental dos resultados. Trabalhos futuros poderiam incluir:\n") # [cite: 184]
    report_content.append("- A incorporação de mais características de polímeros (ex: peso molecular, grau de desacetilação) para modelos mais precisos e holísticos do comportamento do biopolímero.\n") # [cite: 184]
    report_content.append("- A exploração de técnicas de otimização multi-objetivo para balancear Cw e Mp simultaneamente, e métodos mais avançados para lidar com variáveis categóricas na otimização de forma integrada.\n") # [cite: 184]
    report_content.append("- Validação experimental rigorosa das formulações otimizadas no laboratório para confirmar as previsões do modelo e refinar ainda mais os parâmetros ótimos.\n\n") # [cite: 184]

    # Salvar o relatório
    report_file_path = os.path.join(reports_dir, "relatorio_biopolimeros_detalhado.md")
    with open(report_file_path, "w", encoding="utf-8") as f: # [cite: 52]
        f.writelines(report_content) # [cite: 53]
    print(f"Relatório detalhado gerado em {report_file_path}") # [cite: 53]
if __name__ == "__main__":
    data_directory = 'biopolymer_analysis_data'
    reports_directory = 'biopolymer_analysis/reports'

    # Create reports directory if it doesn't exist
    os.makedirs(reports_directory, exist_ok=True)

    # Global collector for report data
    report_data_collector = {
        'initial_data_info': {},
        'cleaned_data_info': {},
        'consolidated_data_info': {
            'absorcao_info': None, 'absorcao_head': None, 'absorcao_describe': None, 'absorcao_nan': None,
            'perda_info': None, 'perda_head': None, 'perda_describe': None, 'perda_nan': None
        },
        'eda_insights': [],
        'eda_image_references': [],
        'model_evaluation': {},
        'feature_importance_abs': None,
        'feature_importance_perda': None,
        'simulation_results': [],
        'optimization_results': {}
    }

    # Consolidar dados de absorção
    df_absorcao_consolidado = consolidate_absorption_data(data_directory)

    # Consolidar dados de perda de massa
    df_perda_consolidado = consolidate_mass_loss_data(data_directory)

    # Carregar e processar dados de métodos de obtenção
    df_metodos_obtencao = load_and_process_methods_data(data_directory)

    # Transformar dados de absorção para formato longo
    id_vars_absorcao = ['id_amostra', 'massa_seca_inicial', 'Tipo_Liquido', 'metodo'] # [cite: 35]
    value_vars_prefix_absorcao_mass = ['massa_umida_final_'] # [cite: 36]
    value_vars_prefix_absorcao_cw = ['Cw_'] # [cite: 36]

    df_absorcao_mass_long = transform_to_long_format(df_absorcao_consolidado, id_vars_absorcao, value_vars_prefix_absorcao_mass, 'Massa_Umida_Final_Unificado', 'Tempo_h') # [cite: 36]
    df_absorcao_cw_long = transform_to_long_format(df_absorcao_consolidado, id_vars_absorcao, value_vars_prefix_absorcao_cw, 'CW_gg_Unificado', 'Tempo_h') # [cite: 36]

    # Juntar as colunas de massa e Cw no mesmo DataFrame longo de absorção
    df_absorcao_final = pd.merge(df_absorcao_mass_long, df_absorcao_cw_long, on=id_vars_absorcao + ['Tempo_h'], how='inner') # [cite: 36]
    print("\n--- DataFrame de Absorção Final (Formato Longo) ---")
    print(df_absorcao_final.info())
    print(df_absorcao_final.head())
    print(f"NaNs em df_absorcao_final após transformação para formato longo:\n{df_absorcao_final.isnull().sum()[df_absorcao_final.isnull().sum() > 0]}")

    # Transformar dados de perda de massa para formato longo
    id_vars_perda = ['id_amostra', 'peso_seco_inicial', 'Tipo_Liquido', 'metodo'] # [cite: 37]
    value_vars_prefix_perda_mass = ['peso_seco_final_'] # [cite: 37]
    value_vars_prefix_perda_mp = ['Mp_'] # [cite: 37]

    df_perda_mass_long = transform_to_long_format(df_perda_consolidado, id_vars_perda, value_vars_prefix_perda_mass, 'Peso_Seco_Final_Unificado', 'Tempo_h') # [cite: 37]
    df_perda_mp_long = transform_to_long_format(df_perda_consolidado, id_vars_perda, value_vars_prefix_perda_mp, 'Mp_Percentual_Unificado', 'Tempo_h') # [cite: 37]

    # Juntar as colunas de peso e Mp no mesmo DataFrame longo de perda de massa
    df_perda_final = pd.merge(df_perda_mass_long, df_perda_mp_long, on=id_vars_perda + ['Tempo_h'], how='inner') # [cite: 37]
    print("\n--- DataFrame de Perda de Massa Final (Formato Longo) ---")
    print(df_perda_final.info())
    print(df_perda_final.head())
    print(f"NaNs em df_perda_final após transformação para formato longo:\n{df_perda_final.isnull().sum()[df_perda_final.isnull().sum() > 0]}") # [cite: 38]

    # Integrar com dados de métodos de obtenção
    df_absorcao_integrado = integrate_data(df_absorcao_final, df_metodos_obtencao) # [cite: 38]
    df_perda_integrado = integrate_data(df_perda_final, df_metodos_obtencao) # [cite: 38]

    # Capture consolidated data info for report
    report_data_collector['consolidated_data_info']['absorcao_info'] = capture_df_info(df_absorcao_integrado)
    report_data_collector['consolidated_data_info']['absorcao_head'] = df_absorcao_integrado.head().to_markdown(index=False, numalign="left", stralign="left")
    report_data_collector['consolidated_data_info']['absorcao_describe'] = capture_df_describe(df_absorcao_integrado)
    report_data_collector['consolidated_data_info']['absorcao_nan'] = df_absorcao_integrado.isnull().sum()[df_absorcao_integrado.isnull().sum() > 0].to_markdown()

    report_data_collector['consolidated_data_info']['perda_info'] = capture_df_info(df_perda_integrado)
    report_data_collector['consolidated_data_info']['perda_head'] = df_perda_integrado.head().to_markdown(index=False, numalign="left", stralign="left")
    report_data_collector['consolidated_data_info']['perda_describe'] = capture_df_describe(df_perda_integrado)
    report_data_collector['consolidated_data_info']['perda_nan'] = df_perda_integrado.isnull().sum()[df_perda_integrado.isnull().sum() > 0].to_markdown()

    print("\n--- DataFrames Finais Integrados ---")
    print("Absorção Integrado:")
    print(df_absorcao_integrado.info())
    print(df_absorcao_integrado.head())
    print(f"NaNs em df_absorcao_integrado após integração:\n{df_absorcao_integrado.isnull().sum()[df_absorcao_integrado.isnull().sum() > 0]}")
    print("\nPerda de Massa Integrado:")
    print(df_perda_integrado.info())
    print(df_perda_integrado.head())
    print(f"NaNs em df_perda_integrado após integração:\n{df_perda_integrado.isnull().sum()[df_perda_integrado.isnull().sum() > 0]}")

    print(f"\nShape de df_absorcao_integrado antes da modelagem: {df_absorcao_integrado.shape}") # [cite: 39]
    print(f"Shape de df_perda_integrado antes da modelagem: {df_perda_integrado.shape}") # [cite: 39]

    # Realizar EDA e gerar visualizações
    perform_eda_and_visualizations(df_absorcao_integrado, df_perda_integrado, reports_directory)

    # Implementar modelos preditivos (usando o dataframe completo, sem amostragem agressiva)
    best_model_abs, best_model_perda, all_model_metrics, X_abs_for_opt, X_perda_for_opt = implement_predictive_models(df_absorcao_integrado, df_perda_integrado, reports_directory) # [cite: 40]

    # Store model results for report
    report_data_collector['model_evaluation'] = all_model_metrics
    report_data_collector['feature_importance_abs'] = all_model_metrics['absorption'].get('Feature_Importance')
    report_data_collector['feature_importance_perda'] = all_model_metrics['mass_loss'].get('Feature_Importance')

    # Run Simulations
    if best_model_abs and best_model_perda and not X_abs_for_opt.empty and not X_perda_for_opt.empty:
        sim_results = run_simulations(best_model_abs, best_model_perda, X_abs_for_opt, X_perda_for_opt, reports_directory)
        report_data_collector['simulation_results'] = sim_results
    else:
        print("Modelos ou dados de template insuficientes para simulações.")

    # Otimização
    if best_model_abs and best_model_perda and not X_abs_for_opt.empty and not X_perda_for_opt.empty: # [cite: 40]
        optimized_params, predicted_cw_opt, predicted_mp_opt, best_categorical_opt_str = optimize_biopolymer_properties(best_model_abs, best_model_perda, X_abs_for_opt, X_perda_for_opt) # [cite: 45]
        report_data_collector['optimization_results'] = {
            'optimized_values': optimized_params,
            'predicted_cw': predicted_cw_opt,
            'predicted_mp': predicted_mp_opt,
            'best_categorical_combination': best_categorical_opt_str
        }
    else:
        print("Modelos preditivos não foram treinados ou dados de template insuficientes, otimização não realizada.")
        report_data_collector['optimization_results'] = {
            'optimized_values': None,
            'predicted_cw': None,
            'predicted_mp': None,
            'best_categorical_combination': "N/A (modelos não treinados ou dados insuficientes)"
        }


    # Gerar o relatório final
    generate_detailed_report_markdown(report_data_collector, reports_directory)
